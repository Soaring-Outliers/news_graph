RES_API = """
<?xml version="1.0" encoding="UTF-8"?>
<results>
    <status>OK</status>
    <usage>By accessing AlchemyAPI or using information generated by AlchemyAPI, you are agreeing to be bound by the AlchemyAPI Terms of Use: http://www.alchemyapi.com/company/terms.html</usage>
    <url>http://www.20minutes.fr/sport/1590259-20150419-coupe-europe-qualification-difficile-toulon-finale-revivre-direct-comme-maison-25-20</url>
    <language>french</language>
    <entities>
        <entity>
            <type>Person</type>
            <relevance>0.457499</relevance>
            <count>1</count>
            <text>Mathieu Bastareaud</text>
        </entity>
        <entity>
            <type>City</type>
            <relevance>0.382419</relevance>
            <count>1</count>
            <text>Twickenham</text>
        </entity>
        <entity>
            <type>Sport</type>
            <relevance>0.363885</relevance>
            <count>1</count>
            <text>Rugby</text>
        </entity>
        <entity>
            <type>HealthCondition</type>
            <relevance>0.362636</relevance>
            <count>1</count>
            <text>Stress</text>
        </entity>
        <entity>
            <type>Region</type>
            <relevance>0.358618</relevance>
            <count>1</count>
            <text>centre</text>
        </entity>
        <entity>
            <type>City</type>
            <relevance>0.31709</relevance>
            <count>1</count>
            <text>Toulon.</text>
        </entity>
    </entities>
</results>
"""

from django.db import models
import os
import urllib
from urllib import request
import xml.etree.ElementTree as ET
import email.utils, datetime

from progress.bar import Bar

class Website(models.Model):
    name = models.CharField(max_length=255)
    url = models.URLField(max_length=255)
    rss_url = models.URLField(max_length=255)
    
    def __str__(self):
        return self.name
    
    def advancement_bar(self,i,n):
        s = "["
        for j in range(n):
            if j <= i:
                s += "#"
            else:
                s += " "
        s += "]"
        print(s)
    
    # Download the rss xml of a website, and extract url of articles from it,
    #   then create object Article if not already present in DB
    def download_rss_articles(self):
        # c <- get rss_url
        with request.urlopen(self.rss_url) as f:
            c = f.read().decode('utf-8')
        # Parse xml @TODO : use cElementTree in place of ElementTree (just pip install change import)
        rss = ET.fromstring(c)
        
        ### Display obtained rss ###
        if False:
            nodes = [(0,rss)]
            while len(nodes) > 0:
                depth, node = nodes.pop()
                s = ""
                for i in range(depth):
                    s += "  "
                if node.text:
                    t = node.text.encode('utf-8')
                    if len(t) > 80:
                        print(s, node.tag, ' :: ', t[:80], "...")
                    else:
                        print(s, node.tag, ' :: ', t)
                else:
                    print(s, node.tag)
                    
                for child in reversed(list(node)):
                    nodes.append((depth+1, child))
        
        # Get all articles links, resolve them and put them into links
        # It last long, so we display a cute advancement bar
        
        links = []
        item_nodes = rss.findall('channel/item')[:1]
        n = len(item_nodes)
        bar = Bar('Creating Articles from '+self.name+' RSS', max=n)
        # For each item, we fetch or create an Article object
        if True:
            for item_node in item_nodes:
                link = item_node.find('link').text
                try:
                    # Try get from DB
                    a = Article.objects.get(rss_url=link)
                except Article.DoesNotExist:
                    # Not in DB, so we resolve the url because a lot of rss feeds give custom url redirecting to true articles
                    # Cookies must be handled because else they redirect you into an infinite loop
                    with request.build_opener(request.HTTPCookieProcessor).open(link) as f:
                        title = item_node.find('title').text
                        desc = item_node.find('description').text
                        pubDate = item_node.find('pubDate').text
                        if pubDate:
                            # rfc822 -> datetime
                            # http://stackoverflow.com/questions/1568856/how-do-i-convert-rfc822-to-a-python-datetime-object
                            pubDate = datetime.datetime.utcfromtimestamp(email.utils.mktime_tz(email.utils.parsedate_tz(pubDate)))
                        try:
                            a = Article(title=title, description=desc, url=f.geturl(), rss_url=link, website=self)
                            a.save()
                        except Exception as e:
                            print("Error:",e)
                            a = None
                if a:
                    links.append(a)
                bar.next()
        print()
        
        return links
        


class Article(models.Model):
    website = models.ForeignKey(Website)
    rss_url = models.URLField(max_length=511)
    url = models.URLField(max_length=511)
    title = models.CharField(max_length=511)
    description = models.TextField(null=True, blank=True)
    date = models.DateTimeField(null=True, blank=True)
    content = models.TextField(null=True, blank=True)
    
    entities_xml = models.TextField(null=True, blank=True)
    
    def __init__(self, *args, **kwargs):
        super(Article, self).__init__(*args, **kwargs)
        #self.fill_alchemy()
    
    # Make queries to AlchemyAPI to complete Article model
    def fill_alchemy(self):
        if self.url:
            if not self.entities_xml:
                endpoint = "http://access.alchemyapi.com/calls/url/URLGetRankedNamedEntities"
                data = {
                    'apikey' : os.environ.get('ALCHEMY_API'),
                    'url' : self.url,
                    'outputMode' : "xml",
                    'showSourceText' : 1,
                }
                url = endpoint + "?" + urllib.parse.urlencode(data)
                #with request.urlopen(url) as f:
                #    c = f.read().decode('utf-8')
                c = RES_API
                self.entities_xml = c
                self.save()
            # Parse entities...
        else:
            print("Error: url is required.")